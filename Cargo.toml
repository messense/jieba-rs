[package]
name = "jieba-rs"
version = "0.6.7"
authors = ["messense <messense@icloud.com>", "Paul Meng <me@paulme.ng>"]
categories = ["text-processing"]
description = "The Jieba Chinese Word Segmentation Implemented in Rust"
keywords = ["nlp", "chinese", "segmenation"]
license = "MIT"
readme = "README.md"
repository = "https://github.com/messense/jieba-rs"
edition = '2018'

[package.metadata.docs.rs]
all-features = true

[dev-dependencies]
criterion = "0.4"
rand = "0.8"
wasm-bindgen-test = "0.3.0"

[target.'cfg(unix)'.dev-dependencies]
jemallocator = "0.5.0"

[[bench]]
name = "jieba_benchmark"
harness = false
required-features = ["tfidf", "textrank"]

[dependencies]
regex = "1.0"
lazy_static = "1.0"
phf = "0.11"
cedarwood = "0.4"
ordered-float = { version = "3.0", optional = true }
once_cell = "1"
fxhash = "0.2.1"

[build-dependencies]
phf_codegen = "0.11"

[features]
default = ["default-dict", "default-hmm-model"]
default-dict = []
default-hmm-model = []
tfidf = ["ordered-float"]
textrank = ["ordered-float"]

[workspace]
members = [
    ".",
    "capi",
    "examples/weicheng"
]
